{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "c0d3edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d64c24ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import get_baseline_data\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras import optimizers, metrics\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "44e3d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notes for group members:\n",
    "# Attention: This model is fitted with a regular validation set. We should actually adjust it in a way that the validation\n",
    "# set consists of a number of randomly selected sequences.\n",
    "# On March 4, this model was also uploaded to Google Drive.\n",
    "# To get the model from Google drive, see the corresponding link in the slack group.\n",
    "\n",
    "data = get_baseline_data(\"raw_data/preproc_data_rate.csv\")\n",
    "data_wo_date = data.drop(columns=\"Date\")\n",
    "\n",
    "def subsample_sequence(data, length): # Return a shorter dataframe with specified length\n",
    "    last_possible = data.shape[0] - length\n",
    "    random_start = np.random.randint(0, last_possible)\n",
    "    data_sample = data[random_start: random_start+length]\n",
    "    return data_sample\n",
    "\n",
    "def split_subsample_sequence(data, length): # Return a random sequence of specified length\n",
    "    data_subsample = subsample_sequence(data, length)\n",
    "    y_sample = data_subsample.iloc[length-31:]\n",
    "\n",
    "    X_sample = data_subsample[0:length-31]\n",
    "    X_sample = X_sample.values\n",
    "    return np.array(X_sample), np.array(y_sample)\n",
    "\n",
    "def get_X_y(data, n_sequences, length): # Return a sepcific number of (X,y) samples of specified length for all adm. regions\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(n_sequences):\n",
    "        (xi, yi) = split_subsample_sequence(data, length)\n",
    "        X.append(xi)\n",
    "        y.append(yi)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "def get_train_test(data,n_sequences,length): # Return train and test data\n",
    "\n",
    "    len_ = int(0.8*data.shape[0])\n",
    "    data_train = data[:len_]\n",
    "    data_test = data[len_:]\n",
    "\n",
    "    test_seq = math.floor(n_sequences/4)\n",
    "\n",
    "    X_train, y_train = get_X_y(data_train, n_sequences, length)\n",
    "    X_test, y_test = get_X_y(data_test, test_seq, length)\n",
    "\n",
    "#     X_train = X_train.reshape(X_train.shape[0], X_train.shape[1],1)\n",
    "#     X_test = X_test.reshape(X_test.shape[0], X_test.shape[1],1)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def model(number_of_sequences, input_sequence_length, number_of_regions, prediction_horizon):\n",
    "# number_of_sequences = 1000 # number of data sequences for training\n",
    "# input_sequence_length = 169 # sequence length in training process\n",
    "# number_of_regions = 30 # number of region sin training process\n",
    "# prediction_horizon = 31 # number of predicted days by region\n",
    "#X_train_shape = (number_of_sequences, input_sequence_length, number_of_regions)\n",
    "#y_train_shape = (number_of_sequences, input_sequence_length, number_of_regions)\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(40, return_sequences=False, activation=\"tanh\", input_shape = (input_sequence_length, number_of_regions)))\n",
    "    model.add(layers.RepeatVector(prediction_horizon))\n",
    "    model.add(layers.LSTM(40, return_sequences=True, activation=\"tanh\"))\n",
    "    model.add(layers.TimeDistributed(layers.Dense(number_of_regions,\"relu\")))\n",
    "    model.compile(loss=\"mse\",\n",
    "                optimizer=\"rmsprop\")\n",
    "    return model\n",
    "\n",
    "def fit_model(X_train, y_train, model):\n",
    "    es = EarlyStopping(monitor='val_loss', verbose=1, patience=20, restore_best_weights=True)\n",
    "    hist = model.fit(X_train, y_train, callbacks=[es],epochs = 2000,validation_split =0.3, batch_size=32)\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "66a039c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_baseline_data(\"raw_data/preproc_data_rate.csv\")\n",
    "data_wo_date = data.drop(columns=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "1ece0e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_, X_test, y_test = get_train_test(data,1000,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "adeb7b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_110 (LSTM)             (None, 40)                11360     \n",
      "                                                                 \n",
      " repeat_vector_25 (RepeatVec  (None, 31, 40)           0         \n",
      " tor)                                                            \n",
      "                                                                 \n",
      " lstm_111 (LSTM)             (None, 31, 40)            12960     \n",
      "                                                                 \n",
      " time_distributed_66 (TimeDi  (None, 31, 30)           1230      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,550\n",
      "Trainable params: 25,550\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type Timestamp).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7b/hgztdlzd4k76rwydg33k1vhm0000gn/T/ipykernel_65563/3587589644.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_AK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raw_data/RNN_LSTM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_AK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_AK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type Timestamp)."
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model_AK = keras.models.load_model('raw_data/RNN_LSTM')\n",
    "model_AK.summary()\n",
    "model_AK.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc92565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
